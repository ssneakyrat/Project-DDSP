dataset:
  batch_size: 16
  num_workers: 1
  pin_memory: true
  persistent_workers: true
  train_files: null  # Set to a number for development
  val_files: 10 #null  # Set to a number for development

model:
  hidden_size: 512
  n_layers: 6
  dropout: 0.1
  n_mels: 80
  sample_rate: 24000
  context_window_sec: 2
  hop_length: 240
  win_length: 1024
  fmin: 40
  fmax: 12000
  n_mag_harmonic: 256
  n_mag_noise: 80
  n_harmonics: 150
  n_formants: 4
  n_breath_bands: 8
  use_gradient_checkpointing: false  # Enable to save memory
  
mel_guidance:
  enabled: true
  upper_threshold: 0.5  # Full guidance (0% masking) when loss >= this value
  lower_threshold: 0.1  # Full masking (100%) when loss <= this value
  warmup_epochs: 10     # Use full guidance for this many epochs initially
  scheduler: "linear"   # How to transition between thresholds (linear or exponential)

loss:
  n_ffts: [1024, 512, 256, 128]
  use_mel_loss: true
  mel_weight: 2.0  # Weight for mel spectrogram loss
  use_mss_loss: true
  use_f0_loss: true  
  use_amplitude_loss: true
  amplitude_weight: 0.5

training:
  learning_rate: 0.002
  weight_decay: 0.0001
  lr_scheduler:
    type: "exponential"
    gamma: 0.99
  epochs: 1000000000
  gradient_clip_val: 1.0
  precision: 32  # 16-bit training causes nan

logging:
  log_every_n_steps: 50
  save_dir: "logs"
  name: "singing_voice_model"
  checkpoint_dir: "checkpoints"
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"
  check_val_every_n_epoch: 5
  audio_log_every_n_epoch: 5
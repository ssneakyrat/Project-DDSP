dataset:
  batch_size: 16
  num_workers: 1
  pin_memory: true
  persistent_workers: true
  train_files: null #100  # Set to a number for development
  val_files: 10 #null  # Set to a number for development

model:
  hidden_size: 512
  n_layers: 6
  dropout: 0.1
  n_mels: 80
  sample_rate: 24000
  context_window_sec: 2
  hop_length: 240
  win_length: 1024
  fmin: 40
  fmax: 12000
  n_mag_harmonic: 256
  n_mag_noise: 80
  n_harmonics: 150
  n_formants: 4
  n_breath_bands: 8
  use_gradient_checkpointing: false  # Enable to save memory
  
loss:
  # FFT sizes for multi-resolution spectral analysis
  n_ffts: [1024, 512, 256, 128]
  
  # Component enable/disable flags
  use_mel_loss: false         # Mel-spectrogram based loss
  use_mss_loss: true          # Multi-scale spectral loss
  use_f0_loss: true           # Fundamental frequency loss
  use_amplitude_loss: true    # Harmonic amplitude loss
  use_sc_loss: true           # Spectral convergence loss (used with MSS)
  
  # Component weights
  mel_weight: 1.0             # Weight for mel spectrogram loss
  mss_weight: 1.0             # Weight for multi-scale spectral loss
  f0_weight: 10.0              # Weight for fundamental frequency loss
  amplitude_weight: 300.0       # Weight for harmonic amplitude loss
  sc_weight: 1.0              # Weight for spectral convergence component
  
  # F0 configuration
  f0_log_scale: true          # Use log scale for F0 (better for human perception)

training:
  learning_rate: 0.002
  weight_decay: 0.0001
  lr_scheduler:
    type: "exponential"
    gamma: 0.99
  epochs: 1000000000
  gradient_clip_val: 1.0
  precision: 32  # 16-bit training causes nan

logging:
  log_every_n_steps: 50
  save_dir: "logs"
  name: "singing_voice_model"
  checkpoint_dir: "checkpoints"
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"
  check_val_every_n_epoch: 1
  audio_log_every_n_epoch: 1